{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "# Portafolio de Implementación para: Técnicas y Arquitecturas de Deep Learning\n",
    "\n",
    "- *Juan Carlos Varela Tellez      A01367002*\n",
    "- *Alan Eduardo Aquino Rosas      A01366912*\n",
    "- *Jorge Chávez Badillo           A01749448*\n",
    "- *Amy Murakami Tsutsumi          A01750185*\n",
    "- *Ariadna Jocelyn Guzmán Jiménez A01749373*\n",
    "\n",
    "## Arquitectura\n",
    "\n",
    "La red neuronal fue una RNN. Las redes neuronales recurrentes se utilizan mucho en el ámbito del lenguaje natural procesado debido a que, a comparación de inferencia numérica donde se busca que los datos sean independientes, el input de cualquier problema de lenguaje natural procesado son oraciones cuyas palabras dependen de la palabra anterior e incluso de la palabra siguiente. Es por esto que las RNN son muy utilizadas para este tipo de problemas.\n",
    "Asimismo, el modelo es un modelo sequence-to-sequence. En esencia, nuestra problemática es una de traducción, y este tipo de modelos seq-2-seq consiste en entrenar modelos que tomen un input de un dominio (lenguaje natural) a otro (dialecto SQL).\n",
    "Nuestro texto es insertado en un codificador bidireccional, pero a diferencia de BERT, este modelo cuenta con un decodificador, cuyo input es el estado final del codificador. Antes de entrar al decodificador, nuestro input pasa por una capa de atención. Después de pasar por esta capa de atención, se combina con las palabras incrustadas de SQL así como palabras incrustadas que el modelo puede ir aprendiendo. Esto es porque es posible que nuestro modelo encuentre palabras que puede que no estuvieran al momento de tokenizar nuestros datos. El decodificador al final nos da nuestro comando en SQL.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocesamiento y obtención de datos\n",
    "\n",
    "Antes de comenzar a hacer variaciones de variaciones, tenemos que tener acceso a nuestra base de datos de paráfrasis. La razón por la cual en esta implementación se intentó utilizar lenguaje natural en inglés es por la falta de datos en cualquier otro idioma. Base de datos sacada de [PPDB](http://paraphrase.org/#/) (version pequeña)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import ppdb\n",
    "\n",
    "path = 'C:/Users/jcvar/OneDrive/Escritorio/ppdb-2.0-s-all/ppdb-2.0-s-all.txt'\n",
    "\n",
    "my_dict = ppdb.load_ppdb(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('a', 'tremendous', 'amount'), ('a', 'significant', 'amount'), ('a', 'substantial', 'amount'), ('an', 'enormous', 'amount')}\n",
      "('a', 'tremendous', 'amount')\n",
      "('a', 'significant', 'amount')\n",
      "('a', 'substantial', 'amount')\n",
      "('an', 'enormous', 'amount')\n",
      "<class 'set'>\n",
      "<class 'ppdb.ppdb.TransformationDict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "{('a', 'significant', 'amount'),\n ('a', 'substantial', 'amount'),\n ('a', 'tremendous', 'amount'),\n ('an', 'enormous', 'amount')}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in my_dict[('huge', 'amounts')]:\n",
    "    if type(x) is set:\n",
    "        print(x)\n",
    "        for y in x:\n",
    "            print(y)\n",
    "    print(str(type(x)))\n",
    "my_dict[['huge', 'amounts']][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como funciona esta base de datos es que distintas palabras, frases e incluso oraciones completas, si al momento de pasar por un traductor, terminan diciendo lo mismo, se les considera un parafraseo. Es por eso que en este ejemplo podemos ver que la frase **'huge amounts'** es lo mismo que **'a tremendous amount'** o **'a significant amount'**."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lo siguiente es el aumento de datos utilizando esta base de datos. Lo que hace esta función es reemplazar el numero de palabras que deseas (ngrams). Si deseas un ngram=1, la funcion reemplazará cada palabra individualmente por los 2 sinónimos que nuestra base de datos de paráfrasis considere. En caso de un ngram=2, tomará pares de palabras y reemplazará esta pequeña sub-oración con lo que la base de datos considere los 2 mejores parafraseos. Asimismo, los comandos SQL ligados con cada oración estarán ligados también con las oraciones generadas.\n",
    "Al final hay una función que repite la función anterior con un ngram de 2, 3 y 4.\n",
    "Por último, un pqueño ejemplo de como funciona esta función de aumento de datos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('show me the population with difficulty paying attention or learning simple things, group by population with difficulty paying attention or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc'), ('is demonstrated by the population with difficulty paying attention or learning simple things, group by population with difficulty paying attention or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc'), ('be demonstrated by the population with difficulty paying attention or learning simple things, group by population with difficulty paying attention or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc'), ('show me specific populations with difficulty paying attention or learning simple things, group by population with difficulty paying attention or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc'), ('show me entire populations with difficulty paying attention or learning simple things, group by population with difficulty paying attention or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc'), ('show me the population groups in difficulty paying attention or learning simple things, group by population with difficulty paying attention or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc'), ('show me the population with difficulty given attention or learning simple things, group by population with difficulty paying attention or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc'), ('show me the population with difficulty attaches great importance or learning simple things, group by population with difficulty paying attention or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc'), ('show me the population with difficulty paying attention or learning simple things, group by population groups in difficulty paying attention or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc'), ('show me the population with difficulty paying attention or learning simple things, group by population with difficulty given attention or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc'), ('show me the population with difficulty paying attention or learning simple things, group by population with difficulty attaches great importance or learning simple things in descending order', 'select DISC12 from discapacidad group by DISC12 desc')]\n"
     ]
    }
   ],
   "source": [
    "def ngram_paraphrasing(sentence, pairs, ngram, sql_comand,factor=2):\n",
    "    # Obtiene el largo de la oracion\n",
    "    results = []\n",
    "    length = len(sentence)\n",
    "    # Define cuando parar\n",
    "    for i in range(length - ngram):\n",
    "        subsentence = []\n",
    "        for j in range(ngram):\n",
    "            # Crea la sub-oracion\n",
    "            subsentence.append(sentence[i + j])\n",
    "        # Si no encuentra la sub-oracion generada en la base de datos\n",
    "        if not pairs[subsentence][0]:\n",
    "            continue\n",
    "        # Lo convierte a una lista para poder iterar sobre esta\n",
    "        paraphrase_list = list(pairs[subsentence][0])\n",
    "        # Cada parafraseo encontrado\n",
    "        for paraphrasing in paraphrase_list[0:factor]:\n",
    "            # Se reemplaza las palabras\n",
    "            new_words = sentence[0:i] + list(paraphrasing) + sentence[i + ngram:]\n",
    "            first_pair = ' '.join(new_words)\n",
    "            results.append((first_pair, sql_comand))\n",
    "    return results\n",
    "\n",
    "def sentence_augmentation_paraphrasing(sentence, sql_comand):\n",
    "    sentences = [(sentence, sql_comand)]\n",
    "    words = sentence.split()\n",
    "    sentences += ngram_paraphrasing(words, my_dict, 2, sql_comand)\n",
    "    sentences += ngram_paraphrasing(words, my_dict, 3, sql_comand)\n",
    "    sentences += ngram_paraphrasing(words, my_dict, 4, sql_comand)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "my_sentence = 'show me the population with difficulty paying attention or learning simple things, group by population with difficulty paying attention or learning simple things in descending order'\n",
    "\n",
    "my_sql_comand = 'select DISC12 from discapacidad group by DISC12 desc'\n",
    "\n",
    "print(sentence_augmentation_paraphrasing(my_sentence, my_sql_comand))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aunque hay algunas oraciones que tienen mala gramática, hay varias otras que tienen sentido y se pueden considerar como parafrases."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creacion de variaciones\n",
    "\n",
    "Ahora viene lo interesante, la creación de nuestra propia base de datos para nuestro problema en específico. Debido a la naturaleza de generación de variaciones de variaciones de variaciones, este problema se puede volver muy complejo muy rápido. Es por esto que se creó una pequeña clase llamada **Table**. Esta clase nos va a ayudar a modularizar cosas como el nombre de cada tabla, nombre de sus respectivas columnas y como referirse a cada columna en lenguaje natural."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Table:\n",
    "    def __init__(self, name, columns):\n",
    "        self.name = name\n",
    "        self.columns = columns\n",
    "        self.natural_columns = ''\n",
    "\n",
    "    def set_natural_columns(self, natural_columns):\n",
    "        self.natural_columns = natural_columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con ayuda de la libreria pandas, podremos obtener el nombre de las columnas y ponerlas de forma automática."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import  pandas\n",
    "import os\n",
    "\n",
    "tables = []\n",
    "\n",
    "# Checa todas las tablas en la carpeta\n",
    "for filename in os.listdir('Data'):\n",
    "    # Obtiene la ubicación del archivo\n",
    "    path = os.path.join(os.getcwd(), 'Data', filename)\n",
    "    # Abre el archivo\n",
    "    with open(path) as f:\n",
    "        # Cuenta el numero de columnas para que se pueda saltar la primera columan\n",
    "        num_cols = len(f.readline().split(','))\n",
    "    # Obtiene los datus\n",
    "    df = pandas.read_csv(path, usecols=range(1, num_cols))\n",
    "    # Da nombre y lista de columnas\n",
    "    table = Table(filename[0:-4], list(df.columns))\n",
    "    tables.append(table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para la obtención de como se llamarían las columnas en un lenguaje natural, este trabajo se tuvo que hacer manual"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "natural_cols_dis = ['state',\n",
    "                    'handicapped population',\n",
    "                    'femenine handicapped population',\n",
    "                    'masculine handicapped population',\n",
    "                    'handicapped population aged between 0 and 14',\n",
    "                    'handicapped population aged between 15 and 59',\n",
    "                    'handicapped population aged 60 and over',\n",
    "                    'population with difficulty walking or moving',\n",
    "                    'population with difficulty seeing even with glasses',\n",
    "                    'population with difficulty speaking, communicating or conversing',\n",
    "                    'population with hearing difficulty',\n",
    "                    'population with difficulty getting dressed, bathing or eating',\n",
    "                    'population with difficulty paying attention or learning simple things',\n",
    "                    'population with mental difficulties',\n",
    "                    'handicapped population entitled to health services']\n",
    "\n",
    "natural_cols_econ = ['state',\n",
    "                     'economically active population',\n",
    "                     'femenine economically active population',\n",
    "                     'masculine economically active population',\n",
    "                     'non-economically active population',\n",
    "                     'femenine non-economically active population',\n",
    "                     'masculine non-economically active population',\n",
    "                     'non-economically active population aged 12 and over that is dedicated to studying',\n",
    "                     'non-economically active population aged 12 and over that is dedicated to household chores',\n",
    "                     'non-economically active population aged 12 and over with mental or physical limitations that prevents them from working',\n",
    "                     'non-economically active population with other reasons that prevents them from working']\n",
    "\n",
    "natural_cols_educ = ['state',\n",
    "                     'population aged between 3 and 5 that attends school',\n",
    "                     'population aged between 3 and 5 that does not attend school',\n",
    "                     'population aged between 6 and 11 that attends school',\n",
    "                     'population aged between 6 and 11 that does not attend school',\n",
    "                     'population aged between 12 and 14 that attends school',\n",
    "                     'population aged between 12 and 14 that does not attend school',\n",
    "                     'population aged between 8 and 14 that knows how to read and write',\n",
    "                     'population aged between 8 and 14 that does not know how to read and write',\n",
    "                     'population aged 15 and over that knows how to read and write',\n",
    "                     'population aged 15 and over that does not know how to read and write',\n",
    "                     'population aged 15 and over without schooling']\n",
    "\n",
    "natural_cols_fecu = ['state',\n",
    "                     'average number of children born alive',\n",
    "                     'average number of children born alive from women aged between 15 and 49',\n",
    "                     'percentage of women aged between 15 and 19 with at least 1 child born alive']\n",
    "\n",
    "natural_cols_habl = ['state',\n",
    "                     'population aged between 5 and 130 that speaks an indigenous language',\n",
    "                     'population aged over 5 that speaks an indigenous language and does not speak spanish',\n",
    "                     'population aged over 5 that speaks an indigenous language and spanish',\n",
    "                     'population in indigenous households']\n",
    "\n",
    "natural_cols_migr = ['state',\n",
    "                     'population born in the state',\n",
    "                     'femenine population born in the state',\n",
    "                     'masculine population born in the state',\n",
    "                     'population born in another state',\n",
    "                     'masculine population born in another state',\n",
    "                     'femenine population born in another state',\n",
    "                     'population born in another country']\n",
    "\n",
    "natural_cols_mort = ['state',\n",
    "                     'percentage of stillborn children from women aged 12 and over']\n",
    "\n",
    "natural_cols_pobl = ['state',\n",
    "                     'total population',\n",
    "                     'total femenine population',\n",
    "                     'total masculine population',\n",
    "                     'population aged between 0 and 2',\n",
    "                     'population aged between 3 and 5',\n",
    "                     'population aged between 6 and 11',\n",
    "                     'population aged between 12 and 14',\n",
    "                     'population aged between 15 and 29',\n",
    "                     'population aged between 30 and 49',\n",
    "                     'population aged between 50 and 59',\n",
    "                     'population aged between 60 and 64',\n",
    "                     'population aged 65 and over']\n",
    "\n",
    "natural_cols_reli = ['state',\n",
    "                     'population with catholic religion',\n",
    "                     'population with protestant, evangelic or biblical religion',\n",
    "                     'population with other religion',\n",
    "                     'population with no religion']\n",
    "\n",
    "natural_cols_salu = ['state',\n",
    "                     'population entitle to health services',\n",
    "                     'population not entitled to health services',\n",
    "                     'population entitled to IMSS health services',\n",
    "                     'population entitled to ISSSTE or state-owned ISSSTE health services',\n",
    "                     'population entitled to popular insurance or new generation medical insurance',\n",
    "                     'population entitled to Pemex, Sedena or Semar health services']\n",
    "\n",
    "natural_cols_situ = ['state',\n",
    "                     'single population aged 12 and over',\n",
    "                     'married or joined population aged 12 and over',\n",
    "                     'formerly married or joinned population aged 12 and over',\n",
    "                     'married or joined population aged between 15 and 24']\n",
    "\n",
    "tables[0].set_natural_columns(natural_cols_dis)\n",
    "tables[1].set_natural_columns(natural_cols_econ)\n",
    "tables[2].set_natural_columns(natural_cols_educ)\n",
    "tables[3].set_natural_columns(natural_cols_fecu)\n",
    "tables[4].set_natural_columns(natural_cols_habl)\n",
    "tables[5].set_natural_columns(natural_cols_migr)\n",
    "tables[6].set_natural_columns(natural_cols_mort)\n",
    "tables[7].set_natural_columns(natural_cols_pobl)\n",
    "tables[8].set_natural_columns(natural_cols_reli)\n",
    "tables[9].set_natural_columns(natural_cols_salu)\n",
    "tables[10].set_natural_columns(natural_cols_situ)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Las variaciones de lenguaje natural y comandos SQL, y sus repectivas variaciones tambien se tuvieron que hacer de forma manual. Se tuvo mucho cuidado al momento de escribirlas ya que es necesario que el índice de las órdenes en lenguaje natural coincidan con su respectivo comando de SQL."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# show me the [col_name] which values are [condition], group by [comp_col] in [order] order\n",
    "# Conditions: less than, more than, equal to\n",
    "\n",
    "variations = ['show me the [col_name]',\n",
    "              'show me the [col_name], group by [comp_col]',\n",
    "              'show me the [col_name], group by [comp_col] in [order] order',\n",
    "              'show me the [col_name] where [condition]',\n",
    "              'show me the [col_name] where [condition] group by [comp_col]',\n",
    "              'show me the [col_name] where [condition] group by [comp_col] in [order] order',\n",
    "              'show me the [col_name] where [condition] in [order] order',\n",
    "              'show me the [col_name] in [order] order']\n",
    "\n",
    "conditions = ['[col_name] is less than [cond_1]',\n",
    "              '[col_name] is more than [cond_1]',\n",
    "              '[col_name] is equal to [cond_1]']\n",
    "\n",
    "order = ['ascending',\n",
    "         'descending']\n",
    "\n",
    "variations_sql = ['select [col_name_sql] from [table]',\n",
    "                  'select [col_name_sql] from [table] group by [comp_col_sql]',\n",
    "                  'select [col_name_sql] from [table] group by [comp_col_sql] [order_sql]',\n",
    "                  'select [col_name_sql] from [table] where [condition_sql]',\n",
    "                  'select [col_name_sql] from [table] where [condition_sql] group by [comp_col_sql]',\n",
    "                  'select [col_name_sql] from [table] where [condition_sql] group by [comp_col_sql] [order_sql]',\n",
    "                  'select [col_name_sql] from [table] where [condition_sql] [order_sql]',\n",
    "                  'select [col_name_sql] from [table] [order_sql]']\n",
    "\n",
    "conditions_sql = ['[col_name_sql] < [cond_1]',\n",
    "                  '[col_name_sql] > [cond_1]',\n",
    "                  '[col_name_sql] = [cond_1]']\n",
    "\n",
    "order_sql = ['asc',\n",
    "             'desc']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Estas son funciones que, de forma iterativa, generan las variaciones de las oraciones. Se modularizaron y la generación de las oraciones y sus respectivos comandos SQL se hara paso por paso."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Obtiene variaciones con columnas de las tablas y sus respectivas variaciones SQL\n",
    "def get_col_names(table:Table, variation:str, variation_sql:str):\n",
    "    pairs = []\n",
    "    for i in range(len(table.columns)):\n",
    "        pair = (variation.replace('[col_name]', table.natural_columns[i]), variation_sql.replace('[col_name_sql]', table.columns[i]).replace('[table]', table.name), table.name)\n",
    "        pairs.append(pair)\n",
    "    return pairs\n",
    "\n",
    "# Genera variaciones de condicinales\n",
    "def replace_condition(pairs:list, conditions:list, conditions_sql:list):\n",
    "    all_pairs = []\n",
    "    for pair in pairs:\n",
    "        if not '[condition]' in pair[0]:\n",
    "            all_pairs.append(pair)\n",
    "            continue\n",
    "        for condition, condition_sql in zip(conditions, conditions_sql):\n",
    "            new_pair = (pair[0].replace('[condition]', condition), pair[1].replace('[condition_sql]', condition_sql), pair[2])\n",
    "            all_pairs.append(new_pair)\n",
    "    return all_pairs\n",
    "\n",
    "# Genera variaciones de orden ascendente o descendente\n",
    "def replace_order(pairs:list, order:list, order_sql:list):\n",
    "    all_pairs = []\n",
    "    for pair in pairs:\n",
    "        if not '[order]' in pair[0]:\n",
    "            all_pairs.append(pair)\n",
    "            continue\n",
    "        for curr_order, curr_order_sql in zip(order, order_sql):\n",
    "            new_pair = (pair[0].replace('[order]', curr_order), pair[1].replace('[order_sql]', curr_order_sql), pair[2])\n",
    "            all_pairs.append(new_pair)\n",
    "    return all_pairs\n",
    "\n",
    "# Remplaza con las columnas complementarias de cada tabla correspondiente\n",
    "def replace_comp_col(pairs:list, tables:list):\n",
    "    all_pairs = []\n",
    "    for pair in pairs:\n",
    "        if not '[comp_col]' in pair[0]:\n",
    "            all_pairs.append(pair)\n",
    "            continue\n",
    "        curr_table = pair[2]\n",
    "        match curr_table:\n",
    "            case 'discapacidad':\n",
    "                for i in range(len(tables[0].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[0].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[0].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'economia':\n",
    "                for i in range(len(tables[1].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[1].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[1].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'educacion':\n",
    "                for i in range(len(tables[2].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[2].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[2].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'fecundidad':\n",
    "                for i in range(len(tables[3].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[3].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[3].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'hablantes':\n",
    "                for i in range(len(tables[4].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[4].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[4].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'migracion':\n",
    "                for i in range(len(tables[5].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[5].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[5].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'mortalidad':\n",
    "                for i in range(len(tables[6].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[6].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[6].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'poblacion':\n",
    "                for i in range(len(tables[7].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[7].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[7].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'religion':\n",
    "                for i in range(len(tables[8].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[8].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[8].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'salud':\n",
    "                for i in range(len(tables[9].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[9].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[9].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'situacion_conyugal':\n",
    "                for i in range(len(tables[10].columns)):\n",
    "                    new_pair = (pair[0].replace('[comp_col]', tables[10].natural_columns[i]), pair[1].replace('[comp_col_sql]', tables[10].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "    return all_pairs\n",
    "\n",
    "# Remplaza con las columnas de cada tabla correspondiente\n",
    "def replace_col_name(pairs:list, tables:list):\n",
    "    all_pairs = []\n",
    "    for pair in pairs:\n",
    "        if not '[col_name]' in pair[0]:\n",
    "            all_pairs.append(pair)\n",
    "            continue\n",
    "        curr_table = pair[2]\n",
    "        match curr_table:\n",
    "            case 'discapacidad':\n",
    "                for i in range(len(tables[0].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[0].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[0].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'economia':\n",
    "                for i in range(len(tables[1].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[1].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[1].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'educacion':\n",
    "                for i in range(len(tables[2].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[2].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[2].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'fecundidad':\n",
    "                for i in range(len(tables[3].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[3].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[3].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'hablantes':\n",
    "                for i in range(len(tables[4].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[4].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[4].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'migracion':\n",
    "                for i in range(len(tables[5].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[5].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[5].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'mortalidad':\n",
    "                for i in range(len(tables[6].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[6].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[6].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'poblacion':\n",
    "                for i in range(len(tables[7].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[7].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[7].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'religion':\n",
    "                for i in range(len(tables[8].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[8].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[8].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'salud':\n",
    "                for i in range(len(tables[9].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[9].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[9].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "            case 'situacion_conyugal':\n",
    "                for i in range(len(tables[10].columns)):\n",
    "                    new_pair = (pair[0].replace('[col_name]', tables[10].natural_columns[i]), pair[1].replace('[col_name_sql]', tables[10].columns[i]), pair[2])\n",
    "                    all_pairs.append(new_pair)\n",
    "    return all_pairs\n",
    "\n",
    "# Utiliza la función anterior con la base de datos de parafraseo para aumentar los datos\n",
    "def augment_pairs(pairs:list):\n",
    "    all_pairs = []\n",
    "    for pair in pairs:\n",
    "        new_pairs = sentence_augmentation_paraphrasing(pair[0], pair[1])\n",
    "        all_pairs += new_pairs\n",
    "    return all_pairs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con todo en su respectivo lugar, queda generar y guardar en un archivo nuestra base de datos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "all_pairs = []\n",
    "for table in tables:\n",
    "    for i in range(len(variations)):\n",
    "        pairs = get_col_names(table, variations[i], variations_sql[i])\n",
    "        all_pairs += pairs\n",
    "\n",
    "all_pairs = replace_condition(all_pairs, conditions, conditions_sql)\n",
    "all_pairs = replace_order(all_pairs, order, order_sql)\n",
    "all_pairs = replace_comp_col(all_pairs, tables)\n",
    "all_pairs = replace_col_name(all_pairs, tables)\n",
    "all_pairs = augment_pairs(all_pairs)\n",
    "\n",
    "with open('variations.txt', 'w') as f:\n",
    "    for pairs in all_pairs:\n",
    "        f.write(pairs[0] + '\\t' + pairs[1] + '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementación del modelo\n",
    "\n",
    "Con la generación de la base de datos completada, es hora de implementar el modelo. Este modelo fue basado en el modelo presentado por Eileen Pangu en [Towards Data Science](https://towardsdatascience.com/end-to-end-attention-based-machine-translation-model-with-minimum-tensorflow-code-ae2f08cc8218) y fue modificado para poder resokver nuestra problemática.\n",
    "Se empieza por separar el dataset en un dataset de lenguaje natural y uno de comandos SQL."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def split(text):\n",
    "    parts = tf.strings.split(text, sep='\\t')\n",
    "    return parts[0], parts[1]\n",
    "\n",
    "full_dataset = tf.data.TextLineDataset(['variations.txt']).map(split)\n",
    "nat_dataset = full_dataset.map(lambda nat, sql: nat)\n",
    "sql_dataset = full_dataset.map(lambda nat, sql: sql)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Después de eso, estandarizamos nuestros datasets para después pasarlos por una capa de Vectorizado de Texto. Y después se adapta esta capa. Al final podemos ver nuestro vocabulario que obtuvimos después de este proceso."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'population', 'and', 'aged', 'by', 'is', 'between', 'the', '[START]', '[END]', 'cond', 'where', 'that', 'group', 'to', 'show', 'me', 'in', 'order', 'than', 'over', 'with', 'not', 'active', 'school', 'does', 'descending', 'ascending', 'handicapped', 'write', 'read', 'how', 'or', 'more', 'noneconomically', 'difficulty', 'state', 'less', ',', 'equal', 'attend', 'attends', 'masculine', 'femenine', 'know', 'knows', 'entitled', 'health', 'services', 'total', 'of', 'born', 'working', 'economically', 'demonstrated', 'from', 'mental', 'general', 'dedicated', 'them', 'prevents', 'be', 'without', 'schooling', 'populations', 'years', 'are', 'attention', 'chores', 'things', 'simple', 'learning', 'other', 'studying', 'household', 'equivalent', 'hearing', 'another', 'difficulties', 'walking', 'moving', 'speaking', 'seeing', 'paying', 'glasses', 'getting', 'even', 'eating', 'dressed', 'conversing', 'communicating', 'bathing', 'was', 'reasons', 'physical', 'limitations', 'indigenous', 'tantamount', 'greater', 'age', 'speaks', 'language', 'insurance', 'an', 'specific', 'entire', 'groups', 'least', 'at', 'religion', 'however', 'given', 'alive', 'spanish', 'women', 'a', 'stateowned', 'emex', 'emar', 'edena', 'five', 'would', 'valued', 'rather', 'much', 'lower', 'lot', 'higher', 'married', 'entitle', 'popular', 'new', 'medical', 'generation', 'children', 'country', 'number', 'average', 'known', 'systems', 'been', 'should', 'devoted', 'joined', 'speak', 'service', 'writing', 'who', 'college', 'replaced', 'follows', 'following', 'as', 'amended', 'able', 'households', 'percentage', 'well', 'hell', 'child', 'reading', 'living', 'prevented', 'receive', 'legally', 'three', 'involved', 'lives', 'healthcare', 'care', 'protestant', 'no', 'evangelic', 'catholic', 'biblical', 'zero', 'it', 'schools', 'actively', 'single', 'joinned', 'formerly', 'lrb', 'two', 'older', 'works', 'have', 'has', 'familiar', 'better', 'countries', 'why', 'this', 'themselves', 'submitted', 'shall', 'prevent', 'pay', 'commit', 'its', 'importance', 'great', 'attaches', 'difficult', 'education', 'primary', 'full', 'amounts', 'rrb', 'sectors', 'industries', 'fourteen', 'm', 'they', 'reason', 'very', 'forward', 'stillborn', 'peoples', 'nations', 'inuit', 'first', 'freedom', 'circumstances', 'used', 'government', 'those', 'different', 'local', 'above', 'operate', 'field', 'experienced', 'proportion', 'were', 'people', 'large', 'high', 'per', 'both', 'within', 's', 'points', 'cent', 'such', 'religious', 'now', 'beliefs', 'one', 'female', 'atleast', 'still', 'twentyfour', 'proportions', 'percentages', 'females', 'languages', 'under', 'ages']\n"
     ]
    }
   ],
   "source": [
    "def standardize(text):\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text\n",
    "\n",
    "nat_text_processor = tf.keras.layers.TextVectorization(standardize=standardize, max_tokens=5000)\n",
    "sql_text_processor = tf.keras.layers.TextVectorization(standardize=standardize, max_tokens=5000)\n",
    "\n",
    "nat_text_processor.adapt(nat_dataset.batch(128))\n",
    "sql_text_processor.adapt(sql_dataset.batch(128))\n",
    "\n",
    "print(nat_text_processor.get_vocabulary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ya que puede que nuestro usuario escriba los comandos de forma diferente, ponemos una capa de incrustación de palabras cuyos pesos estaran congelados. Esto nos va a ayudar a evitar que nuestro modelo se encuentre con palabras que no haya tokenizado o que no se encuentre en el dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "embeddings_index = {}\n",
    "with open('glove.6B/glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "fixed_embedding_matrix = np.zeros((len(nat_text_processor.get_vocabulary()), 100))\n",
    "for i, word in enumerate(nat_text_processor.get_vocabulary()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        fixed_embedding_matrix[i] = embedding_vector\n",
    "\n",
    "fixed_embedding = tf.keras.layers.Embedding(\n",
    "    len(nat_text_processor.get_vocabulary()),\n",
    "    100,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(fixed_embedding_matrix),\n",
    "    trainable=False,\n",
    "    mask_zero=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Después queda crear el modelo. Al momento de crearse, el modelo obtiene el procesador de texto natural, el procesador de comandos sql y la capa de incrustación de palabras congelada.\n",
    "Al momento de que el modelo se manda a llamar (principalmente en entrenamiento), este obtendra los tokens del input, los pasara por el codificador y de ahí obtendrá los estados. Después de esto, se obtendrán los tokens del comando SQL proporcionado. Pasara por la capa atención para despues pasar por el decodificador."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Nl2SqlTranslator(tf.keras.Model):\n",
    "    def __init__(self, nl_text_processor, sql_text_processor, fixed_embedding, unit=128):\n",
    "        super().__init__()\n",
    "        # Natural language\n",
    "        self.nl_text_processor = nl_text_processor\n",
    "        self.nl_voba_size = len(nl_text_processor.get_vocabulary())\n",
    "        self.nl_embedding = tf.keras.layers.Embedding(\n",
    "            self.nl_voba_size,\n",
    "            output_dim=unit,\n",
    "            mask_zero=True)\n",
    "        self.fixed_embedding = fixed_embedding\n",
    "        self.nl_rnn = tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(int(unit/2), return_sequences=True, return_state=True))\n",
    "        # Attention\n",
    "        self.attention = tf.keras.layers.Attention()\n",
    "        # SQL\n",
    "        self.sql_text_processor = sql_text_processor\n",
    "        self.sql_voba_size = len(sql_text_processor.get_vocabulary())\n",
    "        self.sql_embedding = tf.keras.layers.Embedding(\n",
    "            self.sql_voba_size,\n",
    "            output_dim=unit,\n",
    "            mask_zero=True)\n",
    "        self.sql_rnn = tf.keras.layers.LSTM(unit, return_sequences=True, return_state=True)\n",
    "        # Output\n",
    "        self.out = tf.keras.layers.Dense(self.sql_voba_size)\n",
    "\n",
    "    def call(self, nl_text, sql_text, training=True):\n",
    "        nl_tokens = self.nl_text_processor(nl_text)\n",
    "        nl_vectors = self.nl_embedding(nl_tokens, training=training)\n",
    "        nl_fixed_vectors = self.fixed_embedding(nl_tokens)\n",
    "        # nl_combined_vectors = tf.concat([nl_vectors, nl_fixed_vectors], -1)\n",
    "        nl_rnn_out, fhstate, fcstate, bhstate, bcstate = self.nl_rnn(nl_vectors, training=training)\n",
    "        nl_hstate = tf.concat([fhstate, bhstate], -1)\n",
    "        nl_cstate = tf.concat([fcstate, bcstate], -1)\n",
    "\n",
    "        sql_tokens = self.sql_text_processor(sql_text)\n",
    "        expected = sql_tokens[:,1:]\n",
    "\n",
    "        teacher_forcing = sql_tokens[:,:-1]\n",
    "        sql_vectors = self.sql_embedding(teacher_forcing, training=training)\n",
    "        sql_in = self.attention(inputs=[sql_vectors,nl_rnn_out], mask=[sql_vectors._keras_mask, nl_rnn_out._keras_mask], training=training)\n",
    "\n",
    "        trans_vectors, _, _ = self.sql_rnn(sql_in, initial_state=[nl_hstate, nl_cstate], training=training)\n",
    "        out = self.out(trans_vectors, training=training)\n",
    "        return out, expected, out._keras_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora falta entrenarlo. Aquí es donde la implementación toma un giro no optimizado debido al uso de un ciclo **for** para iterar sobre todo nuestro dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def train(epochs, model, batch=64, shuffle=1000):\n",
    "    # Se define la funcion de perdida\n",
    "    loss_fcn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True,\n",
    "        reduction=tf.keras.losses.Reduction.NONE)\n",
    "    # Definicion de algoritmo de optimizacion\n",
    "    opt = tf.keras.optimizers.Adam()\n",
    "    losses = []\n",
    "    # Aleatoriedad en el dataset\n",
    "    ds = full_dataset.shuffle(shuffle).batch(batch).cache()\n",
    "    for epoch in range(epochs):\n",
    "        # Epoch e inicio de toma de tiempo\n",
    "        epoch_losses = []\n",
    "        start_time = time.time()\n",
    "        # Para cada fila en nuestro dataset\n",
    "        for eng_text, spa_text in ds:\n",
    "            # Guarda valores para calculo diferencial mas rapido\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits, expected, mask = model(eng_text, spa_text)\n",
    "                # Termina el proceso de red neuronal y calcula la perdida\n",
    "                loss = loss_fcn(expected, logits)\n",
    "                loss = tf.ragged.boolean_mask(loss, mask)\n",
    "                loss = tf.reduce_sum(loss) * (1. / batch)\n",
    "                epoch_losses.append(loss.numpy())\n",
    "                # Saca gradientes\n",
    "                grads = tape.gradient(loss, model.trainable_weights)\n",
    "                opt.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        # Obtiene perdida al final del epoch\n",
    "        losses.append(np.mean(epoch_losses))\n",
    "        print('Trained epoch: {}; loss: {}'.format(epoch, losses[epoch]))\n",
    "        print(f'Time elapsed in seconds: {time.time() - start_time}')\n",
    "    # Grafica de resultados\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Losses')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora entrenaremos el modelo. Debido a la pobre implementación y gran cantidad de datos a utilizar, el entrenamiento solamente se hará con 5 epochs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained epoch: 0; loss: 0.05051204189658165\n",
      "Time elapsed in seconds: 2356.7697534561157\n",
      "Trained epoch: 1; loss: 0.010642411187291145\n",
      "Time elapsed in seconds: 2313.3394722938538\n",
      "Trained epoch: 2; loss: 0.008154137060046196\n",
      "Time elapsed in seconds: 2306.1291120052338\n",
      "Trained epoch: 3; loss: 0.008491545915603638\n",
      "Time elapsed in seconds: 2331.616354703903\n",
      "Trained epoch: 4; loss: 0.006217396352440119\n",
      "Time elapsed in seconds: 2408.2197473049164\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Nl2SqlTranslator(nat_text_processor, sql_text_processor, fixed_embedding)\n",
    "\n",
    "train(5, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El modelo muestra un rendimiento bastante prometedor, ahora es cuestión de hacer inferencias con el modelo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para poder sacar inferencias, tenemos que hacer el mismo proceso que se hizo al entrenar, pasando por toda la red neuronal, solamente que aqui paramos al momento de obtener los valores del decodificador ya que esa será la predicción de nuestro modelo."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def translate(nat_text, model:Nl2SqlTranslator, max_seq=100):\n",
    "    nl_tokens = model.nl_text_processor([nat_text])\n",
    "    nl_vectors = model.nl_embedding(nl_tokens, training=False)\n",
    "    nl_rnn_out, fhstate, fcstate, bhstate, bcstate = model.nl_rnn(nl_vectors, training=False)\n",
    "    nl_hstate = tf.concat([fhstate, bhstate], -1)\n",
    "    nl_cstate = tf.concat([fcstate, bcstate], -1)\n",
    "    state = [nl_hstate, nl_cstate]\n",
    "    print(nl_rnn_out.shape)\n",
    "\n",
    "    index_from_string = tf.keras.layers.StringLookup(\n",
    "        vocabulary=model.sql_text_processor.get_vocabulary(),\n",
    "        mask_token='')\n",
    "    trans = ['[START]']\n",
    "    vectors = []\n",
    "\n",
    "    for i in range(max_seq):\n",
    "        token = index_from_string([[trans[i]]])\n",
    "        vector = model.sql_embedding(token, training=False)\n",
    "        vectors.append(vector)\n",
    "        query = tf.concat(vectors, axis=1)\n",
    "        context = model.attention(inputs=[query, nl_rnn_out], training=False)\n",
    "        trans_vector, hstate, cstate = model.sql_rnn(context[:,-1:,:], initial_state=state, training=False)\n",
    "        state = [hstate, cstate]\n",
    "        out = model.out(trans_vector)\n",
    "        out = tf.squeeze(out)\n",
    "        word_index = tf.math.argmax(out)\n",
    "        word = model.sql_text_processor.get_vocabulary()[word_index]\n",
    "        trans.append(word)\n",
    "        if word == '[END]':\n",
    "            trans = trans[:-1]\n",
    "            break\n",
    "    _, atts = model.attention(inputs=[vectors, nl_rnn_out], return_attention_scores=True, training=False)\n",
    "    return ' '.join(trans[1:]), atts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora intentemos traducir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2494688461.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn [36], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    Tristemente, nuestro modelo siempre genera un query similar al que se muestra anteriormente. Cada epoch y tiempo de entrenamiento es bastante alto, y para resolver este problema necesitariamos a todo nuestro equipo trabajando en esto, pero nuestro tiempo es limitado y este modelo no es lo único que se debe hacer, es por esto que hasta aqui dejamos este modelo, pero sin no antes reconocer que, con un problema más sencillo, este modelo pudo haber funcionado de maravilla.\u001B[0m\n\u001B[1;37m                         ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print('show me the general population in ascending order')\n",
    "print(translate('show me the general population in ascending order', model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tristemente, nuestro modelo siempre genera un query similar al que se muestra anteriormente. Cada epoch y tiempo de entrenamiento es bastante alto, y para resolver este problema necesitariamos a todo nuestro equipo trabajando en esto, pero nuestro tiempo es limitado y este modelo no es lo único que se debe hacer, es por esto que hasta aqui dejamos este modelo, pero sin no antes reconocer que, con un problema más sencillo, este modelo pudo haber funcionado de maravilla."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}